2014-05-16 15:18:42,844 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:62)] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-16 15:18:45,497 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Maximum n-gram size is: 1
2014-05-16 15:18:45,498 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Minimum LLR value: 1.0
2014-05-16 15:18:45,499 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Number of reduce tasks: 1
2014-05-16 15:18:45,506 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Tokenizing documents in file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/documents/docs.file
2014-05-16 15:18:45,581 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] Initializing JVM Metrics with processName=JobTracker, sessionId=
2014-05-16 15:18:46,554 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:18:46,587 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:18:46,765 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:18:47,760 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local790945754_0001
2014-05-16 15:18:48,099 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins790945754/.staging/job_local790945754_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:18:48,101 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins790945754/.staging/job_local790945754_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:18:49,247 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local790945754_0001/job_local790945754_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:18:49,261 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local790945754_0001/job_local790945754_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:18:49,322 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:18:49,324 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local790945754_0001
2014-05-16 15:18:49,335 (Thread-12) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:18:49,363 (Thread-12) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:18:49,740 (Thread-12) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:18:49,742 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local790945754_0001_m_000000_0
2014-05-16 15:18:50,053 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:18:50,060 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/documents/docs.file:0+99125
2014-05-16 15:18:50,335 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local790945754_0001 running in uber mode : false
2014-05-16 15:18:50,337 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 0% reduce 0%
2014-05-16 15:18:51,116 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:18:51,122 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local790945754_0001_m_000000_0 is done. And is in the process of committing
2014-05-16 15:18:51,153 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:18:51,153 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local790945754_0001_m_000000_0 is allowed to commit now
2014-05-16 15:18:51,156 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local790945754_0001_m_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tokenized-documents/_temporary/0/task_local790945754_0001_m_000000
2014-05-16 15:18:51,160 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:18:51,160 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local790945754_0001_m_000000_0' done.
2014-05-16 15:18:51,162 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local790945754_0001_m_000000_0
2014-05-16 15:18:51,162 (Thread-12) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:18:51,343 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 0%
2014-05-16 15:18:51,344 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local790945754_0001 completed successfully
2014-05-16 15:18:51,477 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 18
	File System Counters
		FILE: Number of bytes read=100109
		FILE: Number of bytes written=412396
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Input split bytes=143
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=514850816
	File Input Format Counters 
		Bytes Read=99909
	File Output Format Counters 
		Bytes Written=97177
2014-05-16 15:18:51,477 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:263)] Creating Term Frequency Vectors
2014-05-16 15:18:51,481 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:307)] Creating dictionary from file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tokenized-documents and saving at file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/wordcount
2014-05-16 15:18:51,553 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:18:51,643 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:18:51,705 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:18:51,863 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:18:52,011 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1558017004_0002
2014-05-16 15:18:52,141 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1558017004/.staging/job_local1558017004_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:18:52,142 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1558017004/.staging/job_local1558017004_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:18:52,483 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1558017004_0002/job_local1558017004_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:18:52,484 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1558017004_0002/job_local1558017004_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:18:52,501 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:18:52,502 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1558017004_0002
2014-05-16 15:18:52,512 (Thread-28) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:18:52,518 (Thread-28) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:18:52,557 (Thread-28) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:18:52,558 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1558017004_0002_m_000000_0
2014-05-16 15:18:52,570 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:18:52,590 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tokenized-documents/part-m-00000:0+96413
2014-05-16 15:18:52,623 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:18:52,760 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:18:52,771 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:18:52,772 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:18:52,772 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:18:52,772 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:18:53,503 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1558017004_0002 running in uber mode : false
2014-05-16 15:18:53,503 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 0% reduce 0%
2014-05-16 15:18:53,713 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:18:53,714 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:18:53,714 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:18:53,714 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 204982; bufvoid = 104857600
2014-05-16 15:18:53,715 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26157916(104631664); length = 56481/6553600
2014-05-16 15:18:55,448 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:18:55,460 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1558017004_0002_m_000000_0 is done. And is in the process of committing
2014-05-16 15:18:55,469 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:18:55,470 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1558017004_0002_m_000000_0' done.
2014-05-16 15:18:55,470 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1558017004_0002_m_000000_0
2014-05-16 15:18:55,471 (Thread-28) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:18:55,482 (Thread-28) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:18:55,482 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1558017004_0002_r_000000_0
2014-05-16 15:18:55,505 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 0%
2014-05-16 15:18:55,546 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:18:55,553 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42133de8
2014-05-16 15:18:55,639 (pool-5-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=360395552, maxSingleShuffleLimit=90098888, mergeThreshold=237861072, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:18:55,678 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1558017004_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:18:55,814 (localfetcher#1) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#1 about to shuffle output of map attempt_local1558017004_0002_m_000000_0 decomp: 177221 len: 177225 to MEMORY
2014-05-16 15:18:55,846 (localfetcher#1) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 177221 bytes from map-output for attempt_local1558017004_0002_m_000000_0
2014-05-16 15:18:55,846 (localfetcher#1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 177221, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->177221
2014-05-16 15:18:55,848 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:18:55,850 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:18:55,852 (pool-5-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:18:55,873 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:18:55,874 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 177215 bytes
2014-05-16 15:18:56,242 (pool-5-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 177221 bytes to disk to satisfy reduce memory limit
2014-05-16 15:18:56,243 (pool-5-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 177225 bytes from disk
2014-05-16 15:18:56,245 (pool-5-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:18:56,245 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:18:56,246 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 177215 bytes
2014-05-16 15:18:56,247 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:18:56,311 (pool-5-thread-1) [INFO - org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1009)] mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2014-05-16 15:18:57,184 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1558017004_0002_r_000000_0 is done. And is in the process of committing
2014-05-16 15:18:57,187 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:18:57,188 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1558017004_0002_r_000000_0 is allowed to commit now
2014-05-16 15:18:57,189 (pool-5-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1558017004_0002_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/wordcount/_temporary/0/task_local1558017004_0002_r_000000
2014-05-16 15:18:57,191 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:18:57,192 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1558017004_0002_r_000000_0' done.
2014-05-16 15:18:57,192 (pool-5-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1558017004_0002_r_000000_0
2014-05-16 15:18:57,192 (Thread-28) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:18:57,507 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:18:57,508 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1558017004_0002 completed successfully
2014-05-16 15:18:57,520 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=749494
		FILE: Number of bytes written=1817906
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=14121
		Map output bytes=204982
		Map output materialized bytes=177225
		Input split bytes=163
		Combine input records=14121
		Combine output records=10300
		Reduce input groups=10300
		Reduce shuffle bytes=177225
		Reduce input records=10300
		Reduce output records=1208
		Spilled Records=20600
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1029701632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=97177
	File Output Format Counters 
		Bytes Written=26063
2014-05-16 15:18:57,758 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:18:57,840 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:18:58,032 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:18:58,161 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:18:58,259 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local675532341_0003
2014-05-16 15:18:58,329 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins675532341/.staging/job_local675532341_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:18:58,330 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins675532341/.staging/job_local675532341_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:18:59,154 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.symlink(LocalDistributedCacheManager.java:207)] Creating symlink: /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/1400278738606/dictionary.file-0 <- /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/dictionary.file-0
2014-05-16 15:18:59,182 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:171)] Localized file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/dictionary.file-0 as file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/1400278738606/dictionary.file-0
2014-05-16 15:18:59,513 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local675532341_0003/job_local675532341_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:18:59,514 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local675532341_0003/job_local675532341_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:18:59,532 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:18:59,532 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local675532341_0003
2014-05-16 15:18:59,539 (Thread-54) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:18:59,541 (Thread-54) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:18:59,560 (Thread-54) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:18:59,561 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local675532341_0003_m_000000_0
2014-05-16 15:18:59,581 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:18:59,584 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tokenized-documents/part-m-00000:0+96413
2014-05-16 15:18:59,585 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:18:59,776 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:18:59,776 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:18:59,776 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:18:59,777 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:18:59,777 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:18:59,937 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:18:59,937 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:18:59,941 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:18:59,941 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 94784; bufvoid = 104857600
2014-05-16 15:18:59,941 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:18:59,959 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:18:59,966 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local675532341_0003_m_000000_0 is done. And is in the process of committing
2014-05-16 15:18:59,975 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:18:59,976 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local675532341_0003_m_000000_0' done.
2014-05-16 15:18:59,976 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local675532341_0003_m_000000_0
2014-05-16 15:18:59,977 (Thread-54) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:18:59,991 (Thread-54) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:18:59,995 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local675532341_0003_r_000000_0
2014-05-16 15:19:00,013 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:00,014 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@14841479
2014-05-16 15:19:00,032 (pool-8-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=360395552, maxSingleShuffleLimit=90098888, mergeThreshold=237861072, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:00,070 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local675532341_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:00,094 (localfetcher#2) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#2 about to shuffle output of map attempt_local675532341_0003_m_000000_0 decomp: 95186 len: 95190 to MEMORY
2014-05-16 15:19:00,095 (localfetcher#2) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 95186 bytes from map-output for attempt_local675532341_0003_m_000000_0
2014-05-16 15:19:00,096 (localfetcher#2) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 95186, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->95186
2014-05-16 15:19:00,097 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:00,107 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:00,107 (pool-8-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:00,112 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:00,113 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 95166 bytes
2014-05-16 15:19:00,117 (pool-8-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 95186 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:00,118 (pool-8-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 95190 bytes from disk
2014-05-16 15:19:00,118 (pool-8-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:00,119 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:00,120 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 95166 bytes
2014-05-16 15:19:00,122 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:00,533 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local675532341_0003 running in uber mode : false
2014-05-16 15:19:00,534 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 0%
2014-05-16 15:19:00,560 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local675532341_0003_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:00,569 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:00,572 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local675532341_0003_r_000000_0 is allowed to commit now
2014-05-16 15:19:00,573 (pool-8-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local675532341_0003_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/partial-vectors-0/_temporary/0/task_local675532341_0003_r_000000
2014-05-16 15:19:00,580 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:00,580 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local675532341_0003_r_000000_0' done.
2014-05-16 15:19:00,580 (pool-8-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local675532341_0003_r_000000_0
2014-05-16 15:19:00,581 (Thread-54) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:01,535 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:01,536 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local675532341_0003 completed successfully
2014-05-16 15:19:01,546 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=1604602
		FILE: Number of bytes written=2885205
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=94784
		Map output materialized bytes=95190
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=95190
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1029701632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=97177
	File Output Format Counters 
		Bytes Written=50897
2014-05-16 15:19:01,581 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:01,643 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:01,790 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:01,811 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:01,894 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1823554899_0004
2014-05-16 15:19:01,977 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1823554899/.staging/job_local1823554899_0004/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:01,982 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1823554899/.staging/job_local1823554899_0004/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:02,171 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1823554899_0004/job_local1823554899_0004.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:02,171 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1823554899_0004/job_local1823554899_0004.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:02,182 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:02,182 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1823554899_0004
2014-05-16 15:19:02,184 (Thread-90) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:02,185 (Thread-90) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:02,202 (Thread-90) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:02,202 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1823554899_0004_m_000000_0
2014-05-16 15:19:02,213 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:02,218 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/partial-vectors-0/part-r-00000:0+50493
2014-05-16 15:19:02,219 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:02,276 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:02,278 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:02,278 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:02,279 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:02,279 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:02,372 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:02,373 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:02,373 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:02,373 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 49183; bufvoid = 104857600
2014-05-16 15:19:02,373 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:02,390 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:02,410 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1823554899_0004_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:02,414 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:02,414 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1823554899_0004_m_000000_0' done.
2014-05-16 15:19:02,414 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1823554899_0004_m_000000_0
2014-05-16 15:19:02,419 (Thread-90) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:02,429 (Thread-90) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:02,430 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1823554899_0004_r_000000_0
2014-05-16 15:19:02,453 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:02,454 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68fb71f2
2014-05-16 15:19:02,460 (pool-11-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=360395552, maxSingleShuffleLimit=90098888, mergeThreshold=237861072, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:02,498 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1823554899_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:02,508 (localfetcher#3) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#3 about to shuffle output of map attempt_local1823554899_0004_m_000000_0 decomp: 49585 len: 49589 to MEMORY
2014-05-16 15:19:02,510 (localfetcher#3) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 49585 bytes from map-output for attempt_local1823554899_0004_m_000000_0
2014-05-16 15:19:02,510 (localfetcher#3) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 49585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49585
2014-05-16 15:19:02,510 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:02,512 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:02,512 (pool-11-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:02,515 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:02,517 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:02,520 (pool-11-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 49585 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:02,520 (pool-11-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 49589 bytes from disk
2014-05-16 15:19:02,521 (pool-11-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:02,521 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:02,521 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:02,522 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:02,817 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1823554899_0004_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:02,835 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:02,842 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1823554899_0004_r_000000_0 is allowed to commit now
2014-05-16 15:19:02,844 (pool-11-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1823554899_0004_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tf-vectors-toprune/_temporary/0/task_local1823554899_0004_r_000000
2014-05-16 15:19:02,846 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:02,852 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1823554899_0004_r_000000_0' done.
2014-05-16 15:19:02,853 (pool-11-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1823554899_0004_r_000000_0
2014-05-16 15:19:02,853 (Thread-90) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:03,183 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1823554899_0004 running in uber mode : false
2014-05-16 15:19:03,184 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:03,185 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1823554899_0004 completed successfully
2014-05-16 15:19:03,201 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=2017430
		FILE: Number of bytes written=3668590
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=49183
		Map output materialized bytes=49589
		Input split bytes=161
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=49589
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=39
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1029701632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50897
	File Output Format Counters 
		Bytes Written=50897
2014-05-16 15:19:03,203 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Deleting file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/partial-vectors-0
2014-05-16 15:19:03,204 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:263)] Calculating IDF
2014-05-16 15:19:03,224 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:03,278 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:03,324 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:03,432 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:03,486 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local893506918_0005
2014-05-16 15:19:03,565 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins893506918/.staging/job_local893506918_0005/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:03,566 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins893506918/.staging/job_local893506918_0005/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:03,811 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local893506918_0005/job_local893506918_0005.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:03,813 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local893506918_0005/job_local893506918_0005.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:03,828 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:03,829 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local893506918_0005
2014-05-16 15:19:03,833 (Thread-110) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:03,835 (Thread-110) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:03,850 (Thread-110) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:03,850 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local893506918_0005_m_000000_0
2014-05-16 15:19:03,859 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:03,862 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tf-vectors-toprune/part-r-00000:0+50493
2014-05-16 15:19:03,863 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:04,042 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:04,043 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:04,043 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:04,043 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:04,043 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:04,093 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:04,094 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:04,102 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:04,102 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 61548; bufvoid = 104857600
2014-05-16 15:19:04,102 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26193884(104775536); length = 20513/6553600
2014-05-16 15:19:04,392 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:04,401 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local893506918_0005_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:04,417 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:04,417 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local893506918_0005_m_000000_0' done.
2014-05-16 15:19:04,417 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local893506918_0005_m_000000_0
2014-05-16 15:19:04,418 (Thread-110) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:04,422 (Thread-110) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:04,422 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local893506918_0005_r_000000_0
2014-05-16 15:19:04,439 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:04,439 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c0f9980
2014-05-16 15:19:04,446 (pool-14-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=360395552, maxSingleShuffleLimit=90098888, mergeThreshold=237861072, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:04,472 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local893506918_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:04,494 (localfetcher#4) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#4 about to shuffle output of map attempt_local893506918_0005_m_000000_0 decomp: 16928 len: 16932 to MEMORY
2014-05-16 15:19:04,495 (localfetcher#4) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 16928 bytes from map-output for attempt_local893506918_0005_m_000000_0
2014-05-16 15:19:04,495 (localfetcher#4) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 16928, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->16928
2014-05-16 15:19:04,495 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:04,496 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:04,497 (pool-14-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:04,500 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:04,500 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 16922 bytes
2014-05-16 15:19:04,504 (pool-14-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 16928 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:04,505 (pool-14-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 16932 bytes from disk
2014-05-16 15:19:04,505 (pool-14-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:04,505 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:04,506 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 16922 bytes
2014-05-16 15:19:04,507 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:04,677 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local893506918_0005_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:04,680 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:04,680 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local893506918_0005_r_000000_0 is allowed to commit now
2014-05-16 15:19:04,681 (pool-14-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local893506918_0005_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/df-count/_temporary/0/task_local893506918_0005_r_000000
2014-05-16 15:19:04,693 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:04,694 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local893506918_0005_r_000000_0' done.
2014-05-16 15:19:04,694 (pool-14-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local893506918_0005_r_000000_0
2014-05-16 15:19:04,694 (Thread-110) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:04,830 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local893506918_0005 running in uber mode : false
2014-05-16 15:19:04,830 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:04,831 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local893506918_0005 completed successfully
2014-05-16 15:19:04,848 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=2252766
		FILE: Number of bytes written=4277545
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=5129
		Map output bytes=61548
		Map output materialized bytes=16932
		Input split bytes=162
		Combine input records=5129
		Combine output records=1209
		Reduce input groups=1209
		Reduce shuffle bytes=16932
		Reduce input records=1209
		Reduce output records=1209
		Spilled Records=2418
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1029701632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50897
	File Output Format Counters 
		Bytes Written=24713
2014-05-16 15:19:04,954 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1009)] mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
2014-05-16 15:19:04,958 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1009)] mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress
2014-05-16 15:19:04,959 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1009)] mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2014-05-16 15:19:04,961 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:05,025 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:05,110 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:05,246 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:05,297 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1804969554_0006
2014-05-16 15:19:05,368 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1804969554/.staging/job_local1804969554_0006/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:05,372 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1804969554/.staging/job_local1804969554_0006/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:05,543 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1804969554_0006/job_local1804969554_0006.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:05,544 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1804969554_0006/job_local1804969554_0006.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:05,550 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:05,551 (Thread-131) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:05,551 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1804969554_0006
2014-05-16 15:19:05,552 (Thread-131) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:05,568 (Thread-131) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:05,568 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1804969554_0006_m_000000_0
2014-05-16 15:19:05,573 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:05,575 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/df-count/part-r-00000:0+24513
2014-05-16 15:19:05,577 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:05,667 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:05,670 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:05,670 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:05,671 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:05,671 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:05,757 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:05,768 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:05,768 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:05,768 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 43488; bufvoid = 104857600
2014-05-16 15:19:05,769 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26199904(104799616); length = 14493/6553600
2014-05-16 15:19:05,833 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:151)] Got brand-new compressor [.deflate]
2014-05-16 15:19:05,898 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:05,917 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1804969554_0006_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:05,927 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:05,928 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1804969554_0006_m_000000_0' done.
2014-05-16 15:19:05,928 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1804969554_0006_m_000000_0
2014-05-16 15:19:05,932 (Thread-131) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:05,948 (Thread-131) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:05,960 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1804969554_0006_r_000000_0
2014-05-16 15:19:05,988 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:05,988 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@927eadd
2014-05-16 15:19:05,996 (pool-17-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=360395552, maxSingleShuffleLimit=90098888, mergeThreshold=237861072, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:06,042 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1804969554_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:06,070 (localfetcher#5) [INFO - org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:179)] Got brand-new decompressor [.deflate]
2014-05-16 15:19:06,077 (localfetcher#5) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#5 about to shuffle output of map attempt_local1804969554_0006_m_000000_0 decomp: 44 len: 41 to MEMORY
2014-05-16 15:19:06,079 (localfetcher#5) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 44 bytes from map-output for attempt_local1804969554_0006_m_000000_0
2014-05-16 15:19:06,079 (localfetcher#5) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 44, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->44
2014-05-16 15:19:06,087 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:06,093 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:06,093 (pool-17-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:06,098 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:06,098 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 38 bytes
2014-05-16 15:19:06,101 (pool-17-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 44 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:06,102 (pool-17-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 49 bytes from disk
2014-05-16 15:19:06,102 (pool-17-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:06,102 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:06,104 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: -1 bytes
2014-05-16 15:19:06,107 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:06,135 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1804969554_0006_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:06,137 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:06,138 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1804969554_0006_r_000000_0 is allowed to commit now
2014-05-16 15:19:06,140 (pool-17-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1804969554_0006_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/stdcalc/_temporary/0/task_local1804969554_0006_r_000000
2014-05-16 15:19:06,143 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:06,143 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1804969554_0006_r_000000_0' done.
2014-05-16 15:19:06,144 (pool-17-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1804969554_0006_r_000000_0
2014-05-16 15:19:06,152 (Thread-131) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:06,552 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1804969554_0006 running in uber mode : false
2014-05-16 15:19:06,553 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:06,554 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1804969554_0006 completed successfully
2014-05-16 15:19:06,572 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=2386052
		FILE: Number of bytes written=4805234
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1209
		Map output records=3624
		Map output bytes=43488
		Map output materialized bytes=41
		Input split bytes=152
		Combine input records=3624
		Combine output records=3
		Reduce input groups=3
		Reduce shuffle bytes=41
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=38
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1029701632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=24713
	File Output Format Counters 
		Bytes Written=167
2014-05-16 15:19:06,608 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:263)] Pruning
2014-05-16 15:19:06,611 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1009)] mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
2014-05-16 15:19:06,618 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1009)] mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress
2014-05-16 15:19:06,618 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1009)] mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2014-05-16 15:19:06,620 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:06,664 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:06,822 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:06,924 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:06,970 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1503023485_0007
2014-05-16 15:19:07,059 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1503023485/.staging/job_local1503023485_0007/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:07,060 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1503023485/.staging/job_local1503023485_0007/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:07,428 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.symlink(LocalDistributedCacheManager.java:207)] Creating symlink: /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/1400278747066/frequency.file-0 <- /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/frequency.file-0
2014-05-16 15:19:07,455 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:171)] Localized file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/frequency.file-0 as file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/1400278747066/frequency.file-0
2014-05-16 15:19:07,598 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1503023485_0007/job_local1503023485_0007.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:07,598 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1503023485_0007/job_local1503023485_0007.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:07,604 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:07,604 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1503023485_0007
2014-05-16 15:19:07,605 (Thread-156) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:07,611 (Thread-156) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:07,634 (Thread-156) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:07,634 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1503023485_0007_m_000000_0
2014-05-16 15:19:07,641 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:07,644 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tf-vectors-toprune/part-r-00000:0+50493
2014-05-16 15:19:07,656 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:07,752 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:07,753 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:07,753 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:07,753 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:07,754 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:07,780 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:07,789 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:07,797 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:07,797 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 49183; bufvoid = 104857600
2014-05-16 15:19:07,797 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:07,819 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:07,840 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1503023485_0007_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:07,851 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:07,854 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1503023485_0007_m_000000_0' done.
2014-05-16 15:19:07,859 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1503023485_0007_m_000000_0
2014-05-16 15:19:07,860 (Thread-156) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:07,877 (Thread-156) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:07,883 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1503023485_0007_r_000000_0
2014-05-16 15:19:07,896 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:07,897 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3114fb83
2014-05-16 15:19:07,905 (pool-20-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=348651520, maxSingleShuffleLimit=87162880, mergeThreshold=230110016, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:07,953 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1503023485_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:07,964 (localfetcher#6) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#6 about to shuffle output of map attempt_local1503023485_0007_m_000000_0 decomp: 49585 len: 8145 to MEMORY
2014-05-16 15:19:07,965 (localfetcher#6) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 49585 bytes from map-output for attempt_local1503023485_0007_m_000000_0
2014-05-16 15:19:07,965 (localfetcher#6) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 49585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49585
2014-05-16 15:19:07,966 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:07,967 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:07,967 (pool-20-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:08,019 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:08,020 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:08,042 (pool-20-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 49585 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:08,043 (pool-20-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 8153 bytes from disk
2014-05-16 15:19:08,043 (pool-20-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:08,043 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:08,044 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 45489 bytes
2014-05-16 15:19:08,045 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:08,235 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1503023485_0007_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:08,238 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:08,242 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1503023485_0007_r_000000_0 is allowed to commit now
2014-05-16 15:19:08,244 (pool-20-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1503023485_0007_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tf-vectors-partial/partial-0/_temporary/0/task_local1503023485_0007_r_000000
2014-05-16 15:19:08,253 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:08,253 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1503023485_0007_r_000000_0' done.
2014-05-16 15:19:08,254 (pool-20-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1503023485_0007_r_000000_0
2014-05-16 15:19:08,254 (Thread-156) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:08,605 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1503023485_0007 running in uber mode : false
2014-05-16 15:19:08,606 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:08,607 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1503023485_0007 completed successfully
2014-05-16 15:19:08,617 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=2578963
		FILE: Number of bytes written=5367959
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=49183
		Map output materialized bytes=8145
		Input split bytes=162
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=8145
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=49
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1005584384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50897
	File Output Format Counters 
		Bytes Written=47248
2014-05-16 15:19:08,629 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:08,686 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:08,731 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:08,832 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:08,878 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1195791878_0008
2014-05-16 15:19:08,953 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1195791878/.staging/job_local1195791878_0008/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:08,955 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1195791878/.staging/job_local1195791878_0008/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:09,305 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1195791878_0008/job_local1195791878_0008.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:09,306 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1195791878_0008/job_local1195791878_0008.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:09,327 (Thread-192) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:09,333 (Thread-192) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:09,327 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:09,337 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1195791878_0008
2014-05-16 15:19:09,340 (Thread-192) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:09,341 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1195791878_0008_m_000000_0
2014-05-16 15:19:09,343 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:09,347 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tf-vectors-partial/partial-0/part-r-00000:0+46872
2014-05-16 15:19:09,348 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:09,460 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:09,475 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:09,477 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:09,478 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:09,478 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:09,490 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:09,491 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:09,492 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:09,492 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 45582; bufvoid = 104857600
2014-05-16 15:19:09,493 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:09,499 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:09,513 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1195791878_0008_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:09,518 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:09,522 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1195791878_0008_m_000000_0' done.
2014-05-16 15:19:09,522 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1195791878_0008_m_000000_0
2014-05-16 15:19:09,523 (Thread-192) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:09,541 (Thread-192) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:09,552 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1195791878_0008_r_000000_0
2014-05-16 15:19:09,569 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:09,570 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7b8363c7
2014-05-16 15:19:09,581 (pool-23-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=354890528, maxSingleShuffleLimit=88722632, mergeThreshold=234227760, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:09,612 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1195791878_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:09,633 (localfetcher#7) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#7 about to shuffle output of map attempt_local1195791878_0008_m_000000_0 decomp: 45982 len: 45986 to MEMORY
2014-05-16 15:19:09,634 (localfetcher#7) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 45982 bytes from map-output for attempt_local1195791878_0008_m_000000_0
2014-05-16 15:19:09,635 (localfetcher#7) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 45982, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->45982
2014-05-16 15:19:09,642 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:09,643 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:09,644 (pool-23-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:09,647 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:09,647 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 45962 bytes
2014-05-16 15:19:09,652 (pool-23-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 45982 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:09,652 (pool-23-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 45986 bytes from disk
2014-05-16 15:19:09,653 (pool-23-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:09,653 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:09,654 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 45962 bytes
2014-05-16 15:19:09,654 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:09,695 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1195791878_0008_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:09,698 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:09,698 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1195791878_0008_r_000000_0 is allowed to commit now
2014-05-16 15:19:09,700 (pool-23-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1195791878_0008_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tf-vectors/_temporary/0/task_local1195791878_0008_r_000000
2014-05-16 15:19:09,701 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:09,702 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1195791878_0008_r_000000_0' done.
2014-05-16 15:19:09,702 (pool-23-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1195791878_0008_r_000000_0
2014-05-16 15:19:09,702 (Thread-192) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:10,337 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1195791878_0008 running in uber mode : false
2014-05-16 15:19:10,338 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:10,339 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1195791878_0008 completed successfully
2014-05-16 15:19:10,348 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=2806742
		FILE: Number of bytes written=6043494
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=45582
		Map output materialized bytes=45986
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=45986
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=49
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1013972992
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=47248
	File Output Format Counters 
		Bytes Written=47248
2014-05-16 15:19:10,349 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Deleting file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tf-vectors-partial
2014-05-16 15:19:10,350 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Deleting file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tf-vectors-toprune
2014-05-16 15:19:10,370 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:10,442 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:10,593 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:10,712 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:10,765 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local275020438_0009
2014-05-16 15:19:10,822 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins275020438/.staging/job_local275020438_0009/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:10,824 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins275020438/.staging/job_local275020438_0009/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:11,271 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.symlink(LocalDistributedCacheManager.java:207)] Creating symlink: /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/1400278750829/frequency.file-0 <- /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/frequency.file-0
2014-05-16 15:19:11,288 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:171)] Localized file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/frequency.file-0 as file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/1400278750829/frequency.file-0
2014-05-16 15:19:11,429 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local275020438_0009/job_local275020438_0009.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:11,432 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local275020438_0009/job_local275020438_0009.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:11,442 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:11,442 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local275020438_0009
2014-05-16 15:19:11,443 (Thread-217) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:11,445 (Thread-217) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:11,462 (Thread-217) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:11,462 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local275020438_0009_m_000000_0
2014-05-16 15:19:11,473 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:11,475 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tf-vectors/part-r-00000:0+46872
2014-05-16 15:19:11,477 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:11,536 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:11,543 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:11,544 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:11,545 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:11,545 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:11,559 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:11,559 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:11,560 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:11,560 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 45582; bufvoid = 104857600
2014-05-16 15:19:11,560 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:11,565 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:11,568 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local275020438_0009_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:11,571 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:11,571 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local275020438_0009_m_000000_0' done.
2014-05-16 15:19:11,572 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local275020438_0009_m_000000_0
2014-05-16 15:19:11,572 (Thread-217) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:11,582 (Thread-217) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:11,582 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local275020438_0009_r_000000_0
2014-05-16 15:19:11,588 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:11,588 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4df6b7c6
2014-05-16 15:19:11,591 (pool-26-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=365900576, maxSingleShuffleLimit=91475144, mergeThreshold=241494384, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:11,593 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local275020438_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:11,597 (localfetcher#8) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#8 about to shuffle output of map attempt_local275020438_0009_m_000000_0 decomp: 45982 len: 45986 to MEMORY
2014-05-16 15:19:11,599 (localfetcher#8) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 45982 bytes from map-output for attempt_local275020438_0009_m_000000_0
2014-05-16 15:19:11,599 (localfetcher#8) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 45982, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->45982
2014-05-16 15:19:11,599 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:11,601 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:11,601 (pool-26-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:11,604 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:11,604 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 45962 bytes
2014-05-16 15:19:11,607 (pool-26-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 45982 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:11,608 (pool-26-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 45986 bytes from disk
2014-05-16 15:19:11,608 (pool-26-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:11,609 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:11,609 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 45962 bytes
2014-05-16 15:19:11,610 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:11,717 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local275020438_0009_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:11,724 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:11,732 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local275020438_0009_r_000000_0 is allowed to commit now
2014-05-16 15:19:11,734 (pool-26-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local275020438_0009_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/partial-vectors-0/_temporary/0/task_local275020438_0009_r_000000
2014-05-16 15:19:11,735 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:11,735 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local275020438_0009_r_000000_0' done.
2014-05-16 15:19:11,735 (pool-26-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local275020438_0009_r_000000_0
2014-05-16 15:19:11,736 (Thread-217) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:12,443 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local275020438_0009 running in uber mode : false
2014-05-16 15:19:12,444 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:12,444 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local275020438_0009 completed successfully
2014-05-16 15:19:12,455 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=3159561
		FILE: Number of bytes written=6813674
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=45582
		Map output materialized bytes=45986
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=45986
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1045430272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=47248
	File Output Format Counters 
		Bytes Written=47248
2014-05-16 15:19:12,458 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:12,557 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:12,622 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:12,729 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:12,872 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1702163309_0010
2014-05-16 15:19:12,943 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1702163309/.staging/job_local1702163309_0010/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:12,948 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/staging/jenkins1702163309/.staging/job_local1702163309_0010/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:13,149 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1702163309_0010/job_local1702163309_0010.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:13,150 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-1636657993818737664/hadoop0.7524054187972478/mapred/local/localRunner/jenkins/job_local1702163309_0010/job_local1702163309_0010.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:13,152 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:13,152 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1702163309_0010
2014-05-16 15:19:13,153 (Thread-253) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:13,154 (Thread-253) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:13,158 (Thread-253) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:13,158 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1702163309_0010_m_000000_0
2014-05-16 15:19:13,161 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:13,163 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/partial-vectors-0/part-r-00000:0+46872
2014-05-16 15:19:13,164 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:13,196 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:13,198 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:13,198 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:13,199 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:13,199 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:13,229 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:13,230 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:13,230 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:13,239 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 45582; bufvoid = 104857600
2014-05-16 15:19:13,239 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:13,253 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:13,261 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1702163309_0010_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:13,276 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:13,277 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1702163309_0010_m_000000_0' done.
2014-05-16 15:19:13,277 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1702163309_0010_m_000000_0
2014-05-16 15:19:13,277 (Thread-253) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:13,282 (Thread-253) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:13,282 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1702163309_0010_r_000000_0
2014-05-16 15:19:13,294 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:13,295 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52ac864
2014-05-16 15:19:13,302 (pool-29-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=365900576, maxSingleShuffleLimit=91475144, mergeThreshold=241494384, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:13,329 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1702163309_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:13,352 (localfetcher#9) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#9 about to shuffle output of map attempt_local1702163309_0010_m_000000_0 decomp: 45982 len: 45986 to MEMORY
2014-05-16 15:19:13,353 (localfetcher#9) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 45982 bytes from map-output for attempt_local1702163309_0010_m_000000_0
2014-05-16 15:19:13,353 (localfetcher#9) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 45982, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->45982
2014-05-16 15:19:13,354 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:13,355 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:13,356 (pool-29-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:13,359 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:13,359 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 45962 bytes
2014-05-16 15:19:13,363 (pool-29-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 45982 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:13,363 (pool-29-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 45986 bytes from disk
2014-05-16 15:19:13,364 (pool-29-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:13,364 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:13,364 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 45962 bytes
2014-05-16 15:19:13,365 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:13,436 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1702163309_0010_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:13,452 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:13,452 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1702163309_0010_r_000000_0 is allowed to commit now
2014-05-16 15:19:13,453 (pool-29-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1702163309_0010_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/tfidf-vectors/_temporary/0/task_local1702163309_0010_r_000000
2014-05-16 15:19:13,461 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:13,462 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1702163309_0010_r_000000_0' done.
2014-05-16 15:19:13,462 (pool-29-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1702163309_0010_r_000000_0
2014-05-16 15:19:13,463 (Thread-253) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:14,153 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1702163309_0010 running in uber mode : false
2014-05-16 15:19:14,154 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:14,155 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1702163309_0010 completed successfully
2014-05-16 15:19:14,168 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=3462992
		FILE: Number of bytes written=7529728
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=45582
		Map output materialized bytes=45986
		Input split bytes=161
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=45986
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1045430272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=47248
	File Output Format Counters 
		Bytes Written=47248
2014-05-16 15:19:14,169 (TEST-HighDFWordsPrunerTest.testHighDFWordsPruning-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Deleting file:/tmp/mahout-HighDFWordsPrunerTest-8841646299968386048/output/partial-vectors-0
2014-05-16 15:19:14,389 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Maximum n-gram size is: 1
2014-05-16 15:19:14,390 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Minimum LLR value: 1.0
2014-05-16 15:19:14,390 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Number of reduce tasks: 1
2014-05-16 15:19:14,391 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Tokenizing documents in file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/documents/docs.file
2014-05-16 15:19:14,420 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:14,469 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:14,471 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:14,536 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:14,596 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1946447783_0011
2014-05-16 15:19:14,672 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1946447783/.staging/job_local1946447783_0011/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:14,689 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1946447783/.staging/job_local1946447783_0011/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:14,918 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1946447783_0011/job_local1946447783_0011.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:14,937 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1946447783_0011/job_local1946447783_0011.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:14,947 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:14,948 (Thread-272) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:14,948 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1946447783_0011
2014-05-16 15:19:14,950 (Thread-272) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:14,968 (Thread-272) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:14,968 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1946447783_0011_m_000000_0
2014-05-16 15:19:14,973 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:14,978 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/documents/docs.file:0+99125
2014-05-16 15:19:15,129 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:15,130 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1946447783_0011_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:15,132 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:15,132 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1946447783_0011_m_000000_0 is allowed to commit now
2014-05-16 15:19:15,138 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1946447783_0011_m_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tokenized-documents/_temporary/0/task_local1946447783_0011_m_000000
2014-05-16 15:19:15,139 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:15,139 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1946447783_0011_m_000000_0' done.
2014-05-16 15:19:15,140 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1946447783_0011_m_000000_0
2014-05-16 15:19:15,140 (Thread-272) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:15,950 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1946447783_0011 running in uber mode : false
2014-05-16 15:19:15,950 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 0%
2014-05-16 15:19:15,951 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1946447783_0011 completed successfully
2014-05-16 15:19:15,956 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 18
	File System Counters
		FILE: Number of bytes read=1993253
		FILE: Number of bytes written=4224713
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Input split bytes=143
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=522715136
	File Input Format Counters 
		Bytes Read=99909
	File Output Format Counters 
		Bytes Written=97177
2014-05-16 15:19:15,956 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:263)] Creating Term Frequency Vectors
2014-05-16 15:19:15,956 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:307)] Creating dictionary from file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tokenized-documents and saving at file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/wordcount
2014-05-16 15:19:15,960 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:16,009 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:16,056 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:16,143 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:16,189 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1067671666_0012
2014-05-16 15:19:16,244 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1067671666/.staging/job_local1067671666_0012/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:16,249 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1067671666/.staging/job_local1067671666_0012/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:16,450 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1067671666_0012/job_local1067671666_0012.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:16,459 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1067671666_0012/job_local1067671666_0012.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:16,462 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:16,462 (Thread-286) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:16,472 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1067671666_0012
2014-05-16 15:19:16,473 (Thread-286) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:16,490 (Thread-286) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:16,492 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1067671666_0012_m_000000_0
2014-05-16 15:19:16,512 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:16,514 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tokenized-documents/part-m-00000:0+96413
2014-05-16 15:19:16,514 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:16,610 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:16,610 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:16,610 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:16,611 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:16,611 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:16,697 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:16,697 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:16,697 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:16,698 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 204982; bufvoid = 104857600
2014-05-16 15:19:16,698 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26157916(104631664); length = 56481/6553600
2014-05-16 15:19:16,797 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:16,804 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1067671666_0012_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:16,813 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:16,821 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1067671666_0012_m_000000_0' done.
2014-05-16 15:19:16,822 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1067671666_0012_m_000000_0
2014-05-16 15:19:16,822 (Thread-286) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:16,831 (Thread-286) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:16,831 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1067671666_0012_r_000000_0
2014-05-16 15:19:16,842 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:16,842 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4044d868
2014-05-16 15:19:16,852 (pool-34-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=357459552, maxSingleShuffleLimit=89364888, mergeThreshold=235923312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:16,889 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1067671666_0012_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:16,892 (localfetcher#10) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#10 about to shuffle output of map attempt_local1067671666_0012_m_000000_0 decomp: 177221 len: 177225 to MEMORY
2014-05-16 15:19:16,894 (localfetcher#10) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 177221 bytes from map-output for attempt_local1067671666_0012_m_000000_0
2014-05-16 15:19:16,894 (localfetcher#10) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 177221, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->177221
2014-05-16 15:19:16,896 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:16,897 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:16,897 (pool-34-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:16,900 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:16,900 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 177215 bytes
2014-05-16 15:19:16,920 (pool-34-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 177221 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:16,920 (pool-34-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 177225 bytes from disk
2014-05-16 15:19:16,921 (pool-34-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:16,921 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:16,921 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 177215 bytes
2014-05-16 15:19:16,923 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:16,976 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1067671666_0012_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:16,987 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:16,987 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1067671666_0012_r_000000_0 is allowed to commit now
2014-05-16 15:19:16,989 (pool-34-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1067671666_0012_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/wordcount/_temporary/0/task_local1067671666_0012_r_000000
2014-05-16 15:19:16,990 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:16,990 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1067671666_0012_r_000000_0' done.
2014-05-16 15:19:16,990 (pool-34-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1067671666_0012_r_000000_0
2014-05-16 15:19:16,991 (Thread-286) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:17,477 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1067671666_0012 running in uber mode : false
2014-05-16 15:19:17,478 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:17,478 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1067671666_0012 completed successfully
2014-05-16 15:19:17,494 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=4535782
		FILE: Number of bytes written=9442540
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=14121
		Map output bytes=204982
		Map output materialized bytes=177225
		Input split bytes=163
		Combine input records=14121
		Combine output records=10300
		Reduce input groups=10300
		Reduce shuffle bytes=177225
		Reduce input records=10300
		Reduce output records=1208
		Spilled Records=20600
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=29
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1021313024
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=97177
	File Output Format Counters 
		Bytes Written=26063
2014-05-16 15:19:17,552 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:17,617 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:17,863 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:17,962 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:18,023 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1186941224_0013
2014-05-16 15:19:18,096 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1186941224/.staging/job_local1186941224_0013/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:18,112 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1186941224/.staging/job_local1186941224_0013/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:18,571 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.symlink(LocalDistributedCacheManager.java:207)] Creating symlink: /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/1400278758152/dictionary.file-0 <- /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/dictionary.file-0
2014-05-16 15:19:18,588 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:171)] Localized file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/dictionary.file-0 as file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/1400278758152/dictionary.file-0
2014-05-16 15:19:18,685 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1186941224_0013/job_local1186941224_0013.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:18,685 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1186941224_0013/job_local1186941224_0013.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:18,687 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:18,687 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1186941224_0013
2014-05-16 15:19:18,688 (Thread-312) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:18,689 (Thread-312) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:18,710 (Thread-312) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:18,713 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1186941224_0013_m_000000_0
2014-05-16 15:19:18,719 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:18,721 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tokenized-documents/part-m-00000:0+96413
2014-05-16 15:19:18,722 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:18,754 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:18,754 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:18,754 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:18,755 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:18,755 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:18,814 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:18,814 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:18,815 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:18,815 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 94784; bufvoid = 104857600
2014-05-16 15:19:18,815 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:18,820 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:18,840 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1186941224_0013_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:18,856 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:18,856 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1186941224_0013_m_000000_0' done.
2014-05-16 15:19:18,857 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1186941224_0013_m_000000_0
2014-05-16 15:19:18,857 (Thread-312) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:18,866 (Thread-312) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:18,868 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1186941224_0013_r_000000_0
2014-05-16 15:19:18,889 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:18,889 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@49b2f5a1
2014-05-16 15:19:18,900 (pool-37-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=365900576, maxSingleShuffleLimit=91475144, mergeThreshold=241494384, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:18,933 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1186941224_0013_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:18,954 (localfetcher#11) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#11 about to shuffle output of map attempt_local1186941224_0013_m_000000_0 decomp: 95186 len: 95190 to MEMORY
2014-05-16 15:19:18,955 (localfetcher#11) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 95186 bytes from map-output for attempt_local1186941224_0013_m_000000_0
2014-05-16 15:19:18,955 (localfetcher#11) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 95186, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->95186
2014-05-16 15:19:18,956 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:18,957 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:18,957 (pool-37-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:18,960 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:18,960 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 95166 bytes
2014-05-16 15:19:18,968 (pool-37-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 95186 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:18,969 (pool-37-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 95190 bytes from disk
2014-05-16 15:19:18,969 (pool-37-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:18,969 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:18,970 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 95166 bytes
2014-05-16 15:19:18,971 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:19,068 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1186941224_0013_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:19,071 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:19,072 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1186941224_0013_r_000000_0 is allowed to commit now
2014-05-16 15:19:19,073 (pool-37-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1186941224_0013_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/partial-vectors-0/_temporary/0/task_local1186941224_0013_r_000000
2014-05-16 15:19:19,083 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:19,083 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1186941224_0013_r_000000_0' done.
2014-05-16 15:19:19,083 (pool-37-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1186941224_0013_r_000000_0
2014-05-16 15:19:19,084 (Thread-312) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:19,688 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1186941224_0013 running in uber mode : false
2014-05-16 15:19:19,689 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:19,690 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1186941224_0013 completed successfully
2014-05-16 15:19:19,699 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=5390890
		FILE: Number of bytes written=10511539
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=94784
		Map output materialized bytes=95190
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=95190
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1044905984
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=97177
	File Output Format Counters 
		Bytes Written=50897
2014-05-16 15:19:19,709 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:19,773 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:19,809 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:19,923 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:19,991 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1255570257_0014
2014-05-16 15:19:20,041 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1255570257/.staging/job_local1255570257_0014/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:20,042 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1255570257/.staging/job_local1255570257_0014/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:20,217 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1255570257_0014/job_local1255570257_0014.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:20,217 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1255570257_0014/job_local1255570257_0014.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:20,219 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:20,220 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1255570257_0014
2014-05-16 15:19:20,219 (Thread-348) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:20,221 (Thread-348) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:20,242 (Thread-348) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:20,242 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1255570257_0014_m_000000_0
2014-05-16 15:19:20,245 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:20,246 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/partial-vectors-0/part-r-00000:0+50493
2014-05-16 15:19:20,247 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:20,323 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:20,323 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:20,323 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:20,324 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:20,324 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:20,360 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:20,360 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:20,361 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:20,361 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 49183; bufvoid = 104857600
2014-05-16 15:19:20,361 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:20,365 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:20,381 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1255570257_0014_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:20,393 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:20,400 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1255570257_0014_m_000000_0' done.
2014-05-16 15:19:20,400 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1255570257_0014_m_000000_0
2014-05-16 15:19:20,401 (Thread-348) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:20,406 (Thread-348) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:20,408 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1255570257_0014_r_000000_0
2014-05-16 15:19:20,423 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:20,423 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@24abf130
2014-05-16 15:19:20,449 (pool-40-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=365533600, maxSingleShuffleLimit=91383400, mergeThreshold=241252192, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:20,500 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1255570257_0014_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:20,509 (localfetcher#12) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#12 about to shuffle output of map attempt_local1255570257_0014_m_000000_0 decomp: 49585 len: 49589 to MEMORY
2014-05-16 15:19:20,510 (localfetcher#12) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 49585 bytes from map-output for attempt_local1255570257_0014_m_000000_0
2014-05-16 15:19:20,510 (localfetcher#12) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 49585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49585
2014-05-16 15:19:20,513 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:20,513 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:20,514 (pool-40-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:20,516 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:20,516 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:20,518 (pool-40-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 49585 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:20,519 (pool-40-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 49589 bytes from disk
2014-05-16 15:19:20,519 (pool-40-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:20,519 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:20,520 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:20,520 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:20,547 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1255570257_0014_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:20,554 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:20,555 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1255570257_0014_r_000000_0 is allowed to commit now
2014-05-16 15:19:20,556 (pool-40-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1255570257_0014_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tf-vectors-toprune/_temporary/0/task_local1255570257_0014_r_000000
2014-05-16 15:19:20,562 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:20,563 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1255570257_0014_r_000000_0' done.
2014-05-16 15:19:20,563 (pool-40-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1255570257_0014_r_000000_0
2014-05-16 15:19:20,563 (Thread-348) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:21,221 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1255570257_0014 running in uber mode : false
2014-05-16 15:19:21,221 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:21,222 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1255570257_0014 completed successfully
2014-05-16 15:19:21,230 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=5803718
		FILE: Number of bytes written=11294924
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=49183
		Map output materialized bytes=49589
		Input split bytes=161
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=49589
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1044381696
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50897
	File Output Format Counters 
		Bytes Written=50897
2014-05-16 15:19:21,231 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Deleting file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/partial-vectors-0
2014-05-16 15:19:21,231 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:263)] Calculating IDF
2014-05-16 15:19:21,234 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:21,288 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:21,339 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:21,446 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:21,545 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local115056037_0015
2014-05-16 15:19:21,610 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins115056037/.staging/job_local115056037_0015/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:21,618 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins115056037/.staging/job_local115056037_0015/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:21,812 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local115056037_0015/job_local115056037_0015.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:21,840 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local115056037_0015/job_local115056037_0015.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:21,848 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:21,849 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local115056037_0015
2014-05-16 15:19:21,851 (Thread-368) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:21,853 (Thread-368) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:21,873 (Thread-368) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:21,873 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local115056037_0015_m_000000_0
2014-05-16 15:19:21,884 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:21,886 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tf-vectors-toprune/part-r-00000:0+50493
2014-05-16 15:19:21,887 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:21,955 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:21,961 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:21,963 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:21,963 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:21,963 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:22,001 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:22,002 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:22,002 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:22,002 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 61548; bufvoid = 104857600
2014-05-16 15:19:22,002 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26193884(104775536); length = 20513/6553600
2014-05-16 15:19:22,086 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:22,113 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local115056037_0015_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:22,121 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:22,122 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local115056037_0015_m_000000_0' done.
2014-05-16 15:19:22,124 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local115056037_0015_m_000000_0
2014-05-16 15:19:22,124 (Thread-368) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:22,133 (Thread-368) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:22,139 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local115056037_0015_r_000000_0
2014-05-16 15:19:22,156 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:22,157 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55e8b9e2
2014-05-16 15:19:22,168 (pool-43-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=366267584, maxSingleShuffleLimit=91566896, mergeThreshold=241736608, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:22,201 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local115056037_0015_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:22,214 (localfetcher#13) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#13 about to shuffle output of map attempt_local115056037_0015_m_000000_0 decomp: 16928 len: 16932 to MEMORY
2014-05-16 15:19:22,215 (localfetcher#13) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 16928 bytes from map-output for attempt_local115056037_0015_m_000000_0
2014-05-16 15:19:22,216 (localfetcher#13) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 16928, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->16928
2014-05-16 15:19:22,222 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:22,223 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:22,223 (pool-43-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:22,225 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:22,226 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 16922 bytes
2014-05-16 15:19:22,228 (pool-43-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 16928 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:22,228 (pool-43-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 16932 bytes from disk
2014-05-16 15:19:22,228 (pool-43-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:22,229 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:22,229 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 16922 bytes
2014-05-16 15:19:22,230 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:22,261 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local115056037_0015_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:22,263 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:22,264 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local115056037_0015_r_000000_0 is allowed to commit now
2014-05-16 15:19:22,265 (pool-43-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local115056037_0015_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/df-count/_temporary/0/task_local115056037_0015_r_000000
2014-05-16 15:19:22,268 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:22,269 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local115056037_0015_r_000000_0' done.
2014-05-16 15:19:22,269 (pool-43-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local115056037_0015_r_000000_0
2014-05-16 15:19:22,269 (Thread-368) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:22,850 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local115056037_0015 running in uber mode : false
2014-05-16 15:19:22,851 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:22,851 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local115056037_0015 completed successfully
2014-05-16 15:19:22,860 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=6039054
		FILE: Number of bytes written=11903879
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=5129
		Map output bytes=61548
		Map output materialized bytes=16932
		Input split bytes=162
		Combine input records=5129
		Combine output records=1209
		Reduce input groups=1209
		Reduce shuffle bytes=16932
		Reduce input records=1209
		Reduce output records=1209
		Spilled Records=2418
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1046478848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50897
	File Output Format Counters 
		Bytes Written=24713
2014-05-16 15:19:22,926 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:263)] Pruning
2014-05-16 15:19:22,928 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1009)] mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
2014-05-16 15:19:22,933 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1009)] mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress
2014-05-16 15:19:22,933 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1009)] mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2014-05-16 15:19:22,935 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:23,013 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:23,173 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:23,302 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:23,371 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local217946256_0016
2014-05-16 15:19:23,412 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins217946256/.staging/job_local217946256_0016/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:23,412 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins217946256/.staging/job_local217946256_0016/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:24,009 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.symlink(LocalDistributedCacheManager.java:207)] Creating symlink: /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/1400278763416/frequency.file-0 <- /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/frequency.file-0
2014-05-16 15:19:24,023 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:171)] Localized file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/frequency.file-0 as file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/1400278763416/frequency.file-0
2014-05-16 15:19:24,150 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local217946256_0016/job_local217946256_0016.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:24,152 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local217946256_0016/job_local217946256_0016.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:24,193 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:24,193 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local217946256_0016
2014-05-16 15:19:24,209 (Thread-394) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:24,213 (Thread-394) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:24,226 (Thread-394) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:24,226 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local217946256_0016_m_000000_0
2014-05-16 15:19:24,243 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:24,246 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tf-vectors-toprune/part-r-00000:0+50493
2014-05-16 15:19:24,247 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:24,319 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:24,322 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:24,322 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:24,322 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:24,322 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:24,341 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:24,341 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:24,342 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:24,342 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 49183; bufvoid = 104857600
2014-05-16 15:19:24,342 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:24,353 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:24,356 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local217946256_0016_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:24,358 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:24,359 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local217946256_0016_m_000000_0' done.
2014-05-16 15:19:24,359 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local217946256_0016_m_000000_0
2014-05-16 15:19:24,359 (Thread-394) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:24,367 (Thread-394) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:24,367 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local217946256_0016_r_000000_0
2014-05-16 15:19:24,384 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:24,384 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@323d1214
2014-05-16 15:19:24,389 (pool-46-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=366634592, maxSingleShuffleLimit=91658648, mergeThreshold=241978848, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:24,413 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local217946256_0016_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:24,427 (localfetcher#14) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#14 about to shuffle output of map attempt_local217946256_0016_m_000000_0 decomp: 49585 len: 8145 to MEMORY
2014-05-16 15:19:24,428 (localfetcher#14) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 49585 bytes from map-output for attempt_local217946256_0016_m_000000_0
2014-05-16 15:19:24,428 (localfetcher#14) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 49585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49585
2014-05-16 15:19:24,430 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:24,432 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:24,432 (pool-46-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:24,434 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:24,435 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:24,453 (pool-46-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 49585 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:24,453 (pool-46-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 8153 bytes from disk
2014-05-16 15:19:24,454 (pool-46-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:24,454 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:24,454 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 45489 bytes
2014-05-16 15:19:24,455 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:24,552 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local217946256_0016_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:24,554 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:24,555 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local217946256_0016_r_000000_0 is allowed to commit now
2014-05-16 15:19:24,556 (pool-46-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local217946256_0016_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tf-vectors-partial/partial-0/_temporary/0/task_local217946256_0016_r_000000
2014-05-16 15:19:24,563 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:24,563 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local217946256_0016_r_000000_0' done.
2014-05-16 15:19:24,563 (pool-46-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local217946256_0016_r_000000_0
2014-05-16 15:19:24,563 (Thread-394) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:25,194 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local217946256_0016 running in uber mode : false
2014-05-16 15:19:25,195 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:25,196 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local217946256_0016 completed successfully
2014-05-16 15:19:25,206 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=6314831
		FILE: Number of bytes written=12559388
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=49183
		Map output materialized bytes=8145
		Input split bytes=162
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=8145
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1047527424
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50897
	File Output Format Counters 
		Bytes Written=50897
2014-05-16 15:19:25,215 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:25,261 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:25,304 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:25,392 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:25,445 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1876921985_0017
2014-05-16 15:19:25,521 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1876921985/.staging/job_local1876921985_0017/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:25,522 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1876921985/.staging/job_local1876921985_0017/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:25,718 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1876921985_0017/job_local1876921985_0017.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:25,719 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1876921985_0017/job_local1876921985_0017.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:25,738 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:25,738 (Thread-430) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:25,739 (Thread-430) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:25,753 (Thread-430) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:25,753 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1876921985_0017_m_000000_0
2014-05-16 15:19:25,753 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1876921985_0017
2014-05-16 15:19:25,763 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:25,765 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tf-vectors-partial/partial-0/part-r-00000:0+50493
2014-05-16 15:19:25,765 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:25,821 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:25,822 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:25,822 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:25,822 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:25,823 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:25,839 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:25,839 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:25,839 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:25,839 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 49183; bufvoid = 104857600
2014-05-16 15:19:25,842 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:25,847 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:25,855 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1876921985_0017_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:25,862 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:25,863 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1876921985_0017_m_000000_0' done.
2014-05-16 15:19:25,863 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1876921985_0017_m_000000_0
2014-05-16 15:19:25,863 (Thread-430) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:25,864 (Thread-430) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:25,864 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1876921985_0017_r_000000_0
2014-05-16 15:19:25,866 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:25,866 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@72cef095
2014-05-16 15:19:25,872 (pool-49-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=366634592, maxSingleShuffleLimit=91658648, mergeThreshold=241978848, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:25,879 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1876921985_0017_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:25,899 (localfetcher#15) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#15 about to shuffle output of map attempt_local1876921985_0017_m_000000_0 decomp: 49585 len: 49589 to MEMORY
2014-05-16 15:19:25,900 (localfetcher#15) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 49585 bytes from map-output for attempt_local1876921985_0017_m_000000_0
2014-05-16 15:19:25,901 (localfetcher#15) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 49585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49585
2014-05-16 15:19:25,901 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:25,904 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:25,904 (pool-49-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:25,907 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:25,907 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:25,913 (pool-49-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 49585 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:25,913 (pool-49-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 49589 bytes from disk
2014-05-16 15:19:25,914 (pool-49-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:25,914 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:25,915 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:25,916 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:25,943 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1876921985_0017_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:25,945 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:25,946 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1876921985_0017_r_000000_0 is allowed to commit now
2014-05-16 15:19:25,947 (pool-49-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1876921985_0017_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tf-vectors/_temporary/0/task_local1876921985_0017_r_000000
2014-05-16 15:19:25,988 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:25,988 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1876921985_0017_r_000000_0' done.
2014-05-16 15:19:25,989 (pool-49-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1876921985_0017_r_000000_0
2014-05-16 15:19:25,989 (Thread-430) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:26,756 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1876921985_0017 running in uber mode : false
2014-05-16 15:19:26,757 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:26,758 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1876921985_0017 completed successfully
2014-05-16 15:19:26,772 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=6557114
		FILE: Number of bytes written=13253030
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=49183
		Map output materialized bytes=49589
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=49589
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1047527424
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50897
	File Output Format Counters 
		Bytes Written=50897
2014-05-16 15:19:26,773 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Deleting file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tf-vectors-partial
2014-05-16 15:19:26,775 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Deleting file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tf-vectors-toprune
2014-05-16 15:19:26,779 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:26,821 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:26,966 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:27,073 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:27,113 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local436484558_0018
2014-05-16 15:19:27,139 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins436484558/.staging/job_local436484558_0018/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:27,139 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins436484558/.staging/job_local436484558_0018/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:27,394 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.symlink(LocalDistributedCacheManager.java:207)] Creating symlink: /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/1400278767144/frequency.file-0 <- /var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/frequency.file-0
2014-05-16 15:19:27,423 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:171)] Localized file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/frequency.file-0 as file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/1400278767144/frequency.file-0
2014-05-16 15:19:27,565 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local436484558_0018/job_local436484558_0018.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:27,566 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local436484558_0018/job_local436484558_0018.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:27,570 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:27,571 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local436484558_0018
2014-05-16 15:19:27,572 (Thread-455) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:27,573 (Thread-455) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:27,576 (Thread-455) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:27,576 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local436484558_0018_m_000000_0
2014-05-16 15:19:27,589 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:27,591 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tf-vectors/part-r-00000:0+50493
2014-05-16 15:19:27,592 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:27,635 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:27,635 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:27,635 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:27,635 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:27,635 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:27,659 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:27,659 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:27,659 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:27,660 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 49183; bufvoid = 104857600
2014-05-16 15:19:27,660 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:27,670 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:27,675 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local436484558_0018_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:27,684 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:27,684 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local436484558_0018_m_000000_0' done.
2014-05-16 15:19:27,684 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local436484558_0018_m_000000_0
2014-05-16 15:19:27,685 (Thread-455) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:27,689 (Thread-455) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:27,689 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local436484558_0018_r_000000_0
2014-05-16 15:19:27,692 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:27,693 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e699d19
2014-05-16 15:19:27,695 (pool-52-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=367368608, maxSingleShuffleLimit=91842152, mergeThreshold=242463296, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:27,695 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local436484558_0018_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:27,698 (localfetcher#16) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#16 about to shuffle output of map attempt_local436484558_0018_m_000000_0 decomp: 49585 len: 49589 to MEMORY
2014-05-16 15:19:27,699 (localfetcher#16) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 49585 bytes from map-output for attempt_local436484558_0018_m_000000_0
2014-05-16 15:19:27,699 (localfetcher#16) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 49585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49585
2014-05-16 15:19:27,700 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] EventFetcher is interrupted.. Returning
2014-05-16 15:19:27,700 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:27,701 (pool-52-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:27,703 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:27,703 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:27,733 (pool-52-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 49585 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:27,734 (pool-52-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 49589 bytes from disk
2014-05-16 15:19:27,734 (pool-52-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:27,734 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:27,734 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:27,735 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:27,811 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local436484558_0018_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:27,813 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:27,813 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local436484558_0018_r_000000_0 is allowed to commit now
2014-05-16 15:19:27,814 (pool-52-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local436484558_0018_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/partial-vectors-0/_temporary/0/task_local436484558_0018_r_000000
2014-05-16 15:19:27,820 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:27,820 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local436484558_0018_r_000000_0' done.
2014-05-16 15:19:27,820 (pool-52-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local436484558_0018_r_000000_0
2014-05-16 15:19:27,821 (Thread-455) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:28,572 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local436484558_0018 running in uber mode : false
2014-05-16 15:19:28,573 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:28,573 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local436484558_0018 completed successfully
2014-05-16 15:19:28,581 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=6931643
		FILE: Number of bytes written=14044924
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=49183
		Map output materialized bytes=49589
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=49589
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1049624576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50897
	File Output Format Counters 
		Bytes Written=50897
2014-05-16 15:19:28,584 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:71)] Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2014-05-16 15:19:28,624 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:259)] No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2014-05-16 15:19:28,662 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:287)] Total input paths to process : 1
2014-05-16 15:19:28,738 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:396)] number of splits:1
2014-05-16 15:19:28,754 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:479)] Submitting tokens for job: job_local1985065994_0019
2014-05-16 15:19:28,779 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1985065994/.staging/job_local1985065994_0019/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:28,780 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/staging/jenkins1985065994/.staging/job_local1985065994_0019/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:28,859 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1985065994_0019/job_local1985065994_0019.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-05-16 15:19:28,860 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [WARN - org.apache.hadoop.conf.Configuration.loadProperty(Configuration.java:2358)] file:/var/lib/jenkins/HiBench/common/mahout-distribution-0.9-cdh5.1.0-SNAPSHOT/core/target/mahout-HighDFWordsPrunerTest-5208146088228457472/hadoop0.9706815755575947/mapred/local/localRunner/jenkins/job_local1985065994_0019/job_local1985065994_0019.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-05-16 15:19:28,862 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.submit(Job.java:1299)] The url to track the job: http://localhost:8080/
2014-05-16 15:19:28,862 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)] Running job: job_local1985065994_0019
2014-05-16 15:19:28,863 (Thread-491) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] OutputCommitter set in config null
2014-05-16 15:19:28,864 (Thread-491) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2014-05-16 15:19:28,868 (Thread-491) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for map tasks
2014-05-16 15:19:28,879 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] Starting task: attempt_local1985065994_0019_m_000000_0
2014-05-16 15:19:28,881 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:28,883 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:733)] Processing split: file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/partial-vectors-0/part-r-00000:0+50493
2014-05-16 15:19:28,884 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:388)] Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-05-16 15:19:28,921 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1182)] (EQUATOR) 0 kvi 26214396(104857584)
2014-05-16 15:19:28,921 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:975)] mapreduce.task.io.sort.mb: 100
2014-05-16 15:19:28,922 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:976)] soft limit at 83886080
2014-05-16 15:19:28,922 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:977)] bufstart = 0; bufvoid = 104857600
2014-05-16 15:19:28,922 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:978)] kvstart = 26214396; length = 6553600
2014-05-16 15:19:28,944 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 
2014-05-16 15:19:28,944 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1437)] Starting flush of map output
2014-05-16 15:19:28,945 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1455)] Spilling map output
2014-05-16 15:19:28,945 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1456)] bufstart = 0; bufend = 49183; bufvoid = 104857600
2014-05-16 15:19:28,945 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1458)] kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
2014-05-16 15:19:28,949 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1641)] Finished spill 0
2014-05-16 15:19:28,962 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1985065994_0019_m_000000_0 is done. And is in the process of committing
2014-05-16 15:19:28,970 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] map
2014-05-16 15:19:28,970 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1985065994_0019_m_000000_0' done.
2014-05-16 15:19:28,970 (LocalJobRunner Map Task Executor #0) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] Finishing task: attempt_local1985065994_0019_m_000000_0
2014-05-16 15:19:28,971 (Thread-491) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] map task executor complete.
2014-05-16 15:19:28,982 (Thread-491) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] Waiting for reduce tasks
2014-05-16 15:19:28,982 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] Starting task: attempt_local1985065994_0019_r_000000_0
2014-05-16 15:19:28,993 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.Task.initialize(Task.java:581)]  Using ResourceCalculatorProcessTree : [ ]
2014-05-16 15:19:28,993 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3d37d68a
2014-05-16 15:19:28,994 (pool-55-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:193)] MergerManager: memoryLimit=367368608, maxSingleShuffleLimit=91842152, mergeThreshold=242463296, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-05-16 15:19:29,005 (localfetcher#17) [INFO - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:140)] localfetcher#17 about to shuffle output of map attempt_local1985065994_0019_m_000000_0 decomp: 49585 len: 49589 to MEMORY
2014-05-16 15:19:29,006 (localfetcher#17) [INFO - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] Read 49585 bytes from map-output for attempt_local1985065994_0019_m_000000_0
2014-05-16 15:19:29,006 (localfetcher#17) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:307)] closeInMemoryFile -> map-output of size: 49585, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->49585
2014-05-16 15:19:29,010 (EventFetcher for fetching Map Completion Events) [INFO - org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] attempt_local1985065994_0019_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2014-05-16 15:19:29,012 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:29,012 (pool-55-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:667)] finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-05-16 15:19:29,014 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:29,015 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:29,017 (pool-55-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:742)] Merged 1 segments, 49585 bytes to disk to satisfy reduce memory limit
2014-05-16 15:19:29,017 (pool-55-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:772)] Merging 1 files, 49589 bytes from disk
2014-05-16 15:19:29,017 (pool-55-thread-1) [INFO - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:787)] Merging 0 segments, 0 bytes from memory into reduce
2014-05-16 15:19:29,018 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:589)] Merging 1 sorted segments
2014-05-16 15:19:29,018 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:688)] Down to the last merge-pass, with 1 segments left of total size: 49565 bytes
2014-05-16 15:19:29,019 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:29,040 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.Task.done(Task.java:995)] Task:attempt_local1985065994_0019_r_000000_0 is done. And is in the process of committing
2014-05-16 15:19:29,042 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] 1 / 1 copied.
2014-05-16 15:19:29,043 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.Task.commit(Task.java:1156)] Task attempt_local1985065994_0019_r_000000_0 is allowed to commit now
2014-05-16 15:19:29,043 (pool-55-thread-1) [INFO - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] Saved output of task 'attempt_local1985065994_0019_r_000000_0' to file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/tfidf-vectors/_temporary/0/task_local1985065994_0019_r_000000
2014-05-16 15:19:29,045 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] reduce > reduce
2014-05-16 15:19:29,045 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.Task.sendDone(Task.java:1115)] Task 'attempt_local1985065994_0019_r_000000_0' done.
2014-05-16 15:19:29,045 (pool-55-thread-1) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] Finishing task: attempt_local1985065994_0019_r_000000_0
2014-05-16 15:19:29,045 (Thread-491) [INFO - org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] reduce task executor complete.
2014-05-16 15:19:29,863 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1365)] Job job_local1985065994_0019 running in uber mode : false
2014-05-16 15:19:29,864 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1372)]  map 100% reduce 100%
2014-05-16 15:19:29,865 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)] Job job_local1985065994_0019 completed successfully
2014-05-16 15:19:29,870 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1390)] Counters: 33
	File System Counters
		FILE: Number of bytes read=7256784
		FILE: Number of bytes written=14782688
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=100
		Map output records=100
		Map output bytes=49183
		Map output materialized bytes=49589
		Input split bytes=161
		Combine input records=0
		Combine output records=0
		Reduce input groups=100
		Reduce shuffle bytes=49589
		Reduce input records=100
		Reduce output records=100
		Spilled Records=200
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1049624576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50897
	File Output Format Counters 
		Bytes Written=50897
2014-05-16 15:19:29,871 (TEST-HighDFWordsPrunerTest.testHighDFWordsPreserving-seed#[F2D20935182F5EF7]) [INFO - org.slf4j.impl.JCLLoggerAdapter.info(JCLLoggerAdapter.java:284)] Deleting file:/tmp/mahout-HighDFWordsPrunerTest-8495201949806248960/output/partial-vectors-0
